{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n",
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{QUESTION 1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "babies = pd.read_csv('babies.csv')\n",
    "cord_clamped = babies['x']\n",
    "not_clamped = babies['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    16.000000\n",
      "mean      9.643750\n",
      "std       1.714631\n",
      "min       8.000000\n",
      "25%       8.350000\n",
      "50%       9.150000\n",
      "75%      10.300000\n",
      "max      13.800000\n",
      "Name: x, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(cord_clamped.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    16.00000\n",
      "mean     12.09375\n",
      "std       2.23591\n",
      "min       8.20000\n",
      "25%      11.00000\n",
      "50%      12.05000\n",
      "75%      13.52500\n",
      "max      16.20000\n",
      "Name: y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(not_clamped.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha1, beta1, alpha2, beta2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='464' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      5.80% [464/8000 00:07&lt;01:55 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # Define noninformative Gamma priors\n",
    "    shape_prior = 0.001\n",
    "    rate_prior = 0.001\n",
    "    alpha1 = pm.Gamma(name=\"alpha1\", alpha=shape_prior, beta=rate_prior)\n",
    "    beta1 = pm.Gamma(name=\"beta1\", alpha=shape_prior, beta=rate_prior)\n",
    "    alpha2 = pm.Gamma(name=\"alpha2\", alpha=shape_prior, beta=rate_prior)\n",
    "    beta2 = pm.Gamma(name=\"beta2\", alpha=shape_prior, beta=rate_prior)\n",
    "    \n",
    "    # Priors for the means\n",
    "    # mean1 = pm.Gamma(name='mean1', alpha=shape_prior, beta=rate_prior)\n",
    "    # mean2 = pm.Gamma(name='mean2', alpha=shape_prior, beta=rate_prior)\n",
    "    mean1, mean2 = alpha1 / beta1, alpha2 / beta2 \n",
    "\n",
    "    # Likelihoods for the data\n",
    "    likelihood1 = pm.Gamma(name='likelihood1', alpha=alpha1, beta=beta1, observed=cord_clamped)\n",
    "    likelihood2 = pm.Gamma(name='likelihood2', alpha=alpha2, beta=beta2, observed=not_clamped)\n",
    "\n",
    "    # Difference in means\n",
    "    diff = mean1 - mean2\n",
    "    diff_means = pm.Deterministic(name='diff_means', var=diff)\n",
    "\n",
    "    # Sampling\n",
    "    trace = pm.sample(draws=1000, tune=1000, target_accept=0.90, cores=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View trace diff_means\n",
    "diff_means_trace = az.summary(data=trace, var_names=['diff_means'], hdi_prob=.90)\n",
    "print(f\"Trace Summary for difference in means:\\n{diff_means_trace}\\n\")\n",
    "\n",
    "# Print trace summary\n",
    "print(f\"Trace Summary:\\n{az.summary(data=trace, hdi_prob=.90)}\\n\")\n",
    "\n",
    "# Check Credible Set\n",
    "print(f\"The 90% Credible Set for the difference of means:\\n{diff_means_trace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{The 90\\% credible set doesn't contain 0.} \\Rightarrow \\text{The difference is statistically significant.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{QUESTION 2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intraocular_pressure = pd.read_excel('iop2.xlsx', header=None, names=['indicator', 'cornea_thickness'])\n",
    "low_iop = intraocular_pressure['indicator']\n",
    "corn_thickness = intraocular_pressure['cornea_thickness']\n",
    "corn_mean = corn_thickness.mean()\n",
    "corn_std = corn_thickness.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(low_iop.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corn_thickness.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrow some code from Aaron's GitHub\n",
    "def standardize(x, mu, sig):\n",
    "        return (x - mu) / (2 * sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{PART A}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrow some code from Aaron's GitHub\n",
    "with pm.Model() as mod_logistic:\n",
    "\n",
    "    # Define x, y\n",
    "    corn_standard = standardize(x=corn_thickness,\n",
    "                                mu=corn_mean,\n",
    "                                sig=corn_std)\n",
    "    corn_data = pm.Data(name=\"corn_data\", \n",
    "                        value=corn_standard, \n",
    "                        mutable=True)\n",
    "    iop_data = pm.Data(name=\"iop_data\", \n",
    "                       value=low_iop, \n",
    "                       mutable=False)\n",
    "\n",
    "    # Define alpha, beta for logistic regression\n",
    "    alpha = pm.Normal(name=\"alpha\", \n",
    "                      mu=0, \n",
    "                      sigma=2)\n",
    "    betas = pm.Normal(name=\"beta\", \n",
    "                      mu=0, \n",
    "                      sigma=1)\n",
    "\n",
    "    logist = alpha + pm.math.dot(l=corn_data, \n",
    "                                 r=betas)\n",
    "    p = pm.math.invlogit(logist)\n",
    "\n",
    "    pm.Bernoulli(name=\"low_iop\", \n",
    "                 p=p, \n",
    "                 observed=iop_data)\n",
    "\n",
    "    trace_log = pm.sample(draws=1000, \n",
    "                          tune=1000, \n",
    "                          cores=None, \n",
    "                          chains=4)\n",
    "\n",
    "# Summarize the trace\n",
    "print(az.summary(data=trace_log,\n",
    "                 hdi_prob=.95))\n",
    "\n",
    "# Get Predictions\n",
    "preds_log = pm.sample_posterior_predictive(trace=trace_log,\n",
    "                                             predictions=True)\n",
    "print(preds_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{PART B}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrow some code from Aaron's GitHub\n",
    "with pm.Model() as mod_logistic_490:\n",
    "\n",
    "    # Define x, y\n",
    "    corn_data = standardize(x=490,\n",
    "                            mu=corn_mean,\n",
    "                            sig=corn_std)\n",
    "    \n",
    "    iop_data = pm.Data(name=\"iop_data\", \n",
    "                       value=low_iop, \n",
    "                       mutable=False)\n",
    "\n",
    "    # Define alpha, beta for logistic regression\n",
    "    alpha = pm.Normal(name=\"alpha\", \n",
    "                      mu=0, \n",
    "                      sigma=2)\n",
    "    betas = pm.Normal(name=\"beta\", \n",
    "                      mu=0, \n",
    "                      sigma=1)\n",
    "\n",
    "    logist = alpha + pm.math.dot(l=corn_data, \n",
    "                                 r=betas)\n",
    "    p = pm.math.invlogit(logist)\n",
    "\n",
    "    pm.Bernoulli(name=\"low_iop\",\n",
    "                p=p,\n",
    "                observed=iop_data)\n",
    "\n",
    "    trace_log490 = pm.sample(draws=1000,\n",
    "                             tune=1000,\n",
    "                             cores=None,\n",
    "                             chains=4)\n",
    "\n",
    "# Summarize the trace\n",
    "print(az.summary(data=trace_log490,\n",
    "                 hdi_prob=.95))\n",
    "\n",
    "# Get Predictions\n",
    "preds_log490 = pm.sample_posterior_predictive(trace=trace_log490,\n",
    "                                             predictions=True)\n",
    "print(preds_log490)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{PART C}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrow some code from Aaron's GitHub\n",
    "with pm.Model() as mod_probit:\n",
    "\n",
    "    # Define x, y\n",
    "    corn_standard = standardize(x=corn_thickness,\n",
    "                                mu=corn_mean,\n",
    "                                sig=corn_std)\n",
    "    corn_data = pm.Data(name=\"corn_data\",\n",
    "                        value=corn_standard,\n",
    "                        mutable=True)\n",
    "    iop_data = pm.Data(name=\"iop_data\",\n",
    "                        value=low_iop,\n",
    "                        mutable=False)\n",
    "\n",
    "    # Define alpha, beta for logistic regression\n",
    "    alpha = pm.Normal(name=\"alpha\",\n",
    "                      mu=0,\n",
    "                      sigma=2)\n",
    "    betas = pm.Normal(name=\"beta\",\n",
    "                      mu=0,\n",
    "                      sigma=1)\n",
    "\n",
    "    logist = alpha + pm.math.dot(l=corn_data,\n",
    "                                 r=betas)\n",
    "    p = pm.math.invprobit(logist)\n",
    "\n",
    "    pm.Bernoulli(name=\"low_iop\",\n",
    "                 p=p,\n",
    "                 observed=iop_data)\n",
    "\n",
    "    trace_prob = pm.sample(draws=1000,\n",
    "                           tune=1000,\n",
    "                           cores=None,\n",
    "                           chains=4,\n",
    "                           idata_kwargs=dict(log_likelihood=True))\n",
    "\n",
    "# Summarize the trace\n",
    "print(az.summary(data=trace_prob,\n",
    "                 hdi_prob=.95))\n",
    "\n",
    "# Get Predictions\n",
    "preds_probs = pm.sample_posterior_predictive(trace=trace_prob,\n",
    "                                             predictions=True)\n",
    "print(preds_probs)\n",
    "\n",
    "# View Deviances\n",
    "print(az.waic(data=trace_prob,\n",
    "              scale=\"deviance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrow some code from Aaron's GitHub\n",
    "with pm.Model() as mod_probit_490:\n",
    "\n",
    "    # Define x, y\n",
    "    corn_data = standardize(x=490,\n",
    "                            mu=corn_mean,\n",
    "                            sig=corn_std)\n",
    "    iop_data = pm.Data(name=\"iop_data\",\n",
    "                       value=low_iop,\n",
    "                       mutable=False)\n",
    "\n",
    "    # Define alpha, beta for logistic regression\n",
    "    alpha = pm.Normal(name=\"alpha\",\n",
    "                      mu=0,\n",
    "                      sigma=2)\n",
    "    betas = pm.Normal(name=\"beta\",\n",
    "                      mu=0,\n",
    "                      sigma=1)\n",
    "\n",
    "    logist = alpha + pm.math.dot(l=corn_data,\n",
    "                                 r=betas)\n",
    "    p = pm.math.invprobit(logist)\n",
    "    \n",
    "    pm.Bernoulli(name=\"low_iop\",\n",
    "                 logit_p=p,\n",
    "                 observed=iop_data)\n",
    "\n",
    "    trace_prob490 = pm.sample(draws=1000,\n",
    "                              tune=1000,\n",
    "                              cores=None,\n",
    "                              chains=4,\n",
    "                              idata_kwargs=dict(log_likelihood=True))\n",
    "\n",
    "# Summarize the trace\n",
    "print(az.summary(data=trace_prob490,\n",
    "                 hdi_prob=.95))\n",
    "\n",
    "# Get Predictions\n",
    "preds_probs490 = pm.sample_posterior_predictive(trace=trace_prob490,\n",
    "                                                predictions=True)\n",
    "print(preds_probs490)\n",
    "\n",
    "# View Deviances\n",
    "print(az.waic(data=trace_prob490,\n",
    "              scale=\"deviance\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{QUESTION 3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micronuclei = pd.read_csv('micronuclei.csv')\n",
    "rad_dose = micronuclei['x']\n",
    "freq = micronuclei['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rad_dose.value_counts())\n",
    "print(rad_dose.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freq.value_counts())\n",
    "print(freq.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{PART A}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pm.Model() as mod_poisson:\n",
    "    \n",
    "#     # Priors for the regression coefficients\n",
    "#     beta = pm.Normal('beta', mu=0, sigma=2)\n",
    "\n",
    "#     # Expected value of the outcome (lambda parameter) using the log link function\n",
    "#     mu = pm.math.exp(pm.math.dot(rad_dose, beta))\n",
    "\n",
    "#     # Likelihood (sampling distribution) of observations\n",
    "#     likelihood = pm.Poisson('likelihood', mu=mu, observed=freq)\n",
    "\n",
    "#     # Use the No-U-Turn Sampler\n",
    "#     trace = pm.sample(draws=1000, tune=1000, cores=None, chains=2)\n",
    "\n",
    "# # Summarize the trace\n",
    "# print(pm.summary(trace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{PART B}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes_stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
